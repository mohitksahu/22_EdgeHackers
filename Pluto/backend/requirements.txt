# Core FastAPI and async
fastapi==0.104.1
uvicorn[standard]==0.24.0
pydantic==2.5.0
pydantic-settings==2.1.0

# Data processing and file handling
PyPDF2>=3.0.0
python-docx>=1.0.0
Pillow>=10.0.0
python-multipart>=0.0.6
PyMuPDF>=1.22.0

# OCR and Audio processing
pytesseract>=0.3.10
faster-whisper>=1.0.0
# Pinned to avoid Numpy 2.0 conflict
opencv-python<4.10.0

# LLM and Embeddings (C++-powered engines, ONNX for CLIP)
# Ensure these are installed with CUDA flags manually as well
llama-cpp-python>=0.3.0
fastembed-gpu>=0.3.0

# Vector Database
chromadb>=0.4.0

# LangChain and LangGraph (Strictly pinned for NumPy 1.x compatibility)
langchain==0.2.17
langchain-community==0.2.19
langgraph>=0.0.15
langchain-openai>=0.1.0

# LLM Integration
openai>=1.0.0

# Integrations
twilio>=8.0.0
langsmith>=0.0.70

# Utilities
python-dotenv>=1.0.0
aiofiles>=23.0.0
httpx>=0.25.0
# CRITICAL: Force NumPy 1.x for LangChain/OpenCV compatibility
numpy>=1.24.0,<2.0.0
pandas>=2.0.0
scikit-learn>=1.3.0
colorama>=0.4.6
rich>=13.0.0

# Development and testing
pytest>=7.4.0
pytest-asyncio>=0.21.0
black>=23.0.0
isort>=5.12.0

#/*"pip uninstall -y llama-cpp-python
#pip cache purge                                                                         
#pip install llama-cpp-python==0.2.90 --only-binary=:all: --extra-index-url https://abetlen.github.io/llama-cpp-python/whl/cu121"*/